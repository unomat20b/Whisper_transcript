{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unomat20b/Whisper_transcript/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRIRsmVN43Zf"
      },
      "outputs": [],
      "source": [
        "pip install openai -whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiEP7vKI_dZc"
      },
      "outputs": [],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV3AWsoY7PN2"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--task translate\n"
      ],
      "metadata": {
        "id": "DY38ldsIXf4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcYPNqpq7d2_"
      },
      "outputs": [],
      "source": [
        "!whisper \"/content/GMT20240408-085909_Recording (1).m4a\" --model medium --language ru"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import datetime\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "rN3BHIgEWwyo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = ''\n",
        "with open('/content/public_key.json', 'r') as file_to_read:\n",
        "    json_data = json.load(file_to_read)\n",
        "    OPENAI_API_KEY = json_data[\"public_key\"]\n",
        "    openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "j9rwz-0yWjt2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kjekj4TkoUV"
      },
      "outputs": [],
      "source": [
        "# Прочитать текстовый файл и разделить его на части\n",
        "with open('/content/GMT20240422-085151_Recording.transcript.vtt', 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "max_tokens_per_part = 6000\n",
        "text_parts = []\n",
        "\n",
        "# Разделение текста на блоки по 4000 токенов\n",
        "for i in range(0, len(text_data), max_tokens_per_part):\n",
        "    text_parts.append(text_data[i:i+max_tokens_per_part])\n",
        "\n",
        "# Отправка частей на анализ и сбор ответов ассистента\n",
        "assistant_responses = []\n",
        "\n",
        "for i, part in enumerate(text_parts):\n",
        "    question = \"расскажи в кратце о чем был разговор, дату время обсуждения\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Вы полезный помощник.\"},\n",
        "        {\"role\": \"user\", \"content\": part},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "    assistant_response = response.choices[0].message['content']\n",
        "    assistant_responses.append(assistant_response)\n",
        "    print(f\"Часть {i+1} обработана\")\n",
        "\n",
        "# Объединение ответов ассистента в один текст\n",
        "full_assistant_response = '\\n'.join(assistant_responses)\n",
        "wrapped_response = textwrap.fill(full_assistant_response, width=80)\n",
        "print(wrapped_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прочитать текстовый файл и разделить его на части\n",
        "with open('/content/Еженедельная встреча первая итерация саммари 22-04-2024 .txt', 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "max_tokens_per_part = 6000\n",
        "text_parts = []\n",
        "\n",
        "# Разделение текста на блоки по 4000 токенов\n",
        "for i in range(0, len(text_data), max_tokens_per_part):\n",
        "    text_parts.append(text_data[i:i+max_tokens_per_part])\n",
        "\n",
        "# Отправка частей на анализ и сбор ответов ассистента\n",
        "assistant_responses = []\n",
        "\n",
        "for i, part in enumerate(text_parts):\n",
        "    question = \"выдели время обсуждения,  Список участников, Повестка онлайн-встречи, краткое содержание разговоров\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Вы полезный помощник.\"},\n",
        "        {\"role\": \"user\", \"content\": part},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "    assistant_response = response.choices[0].message['content']\n",
        "    assistant_responses.append(assistant_response)\n",
        "    print(f\"Часть {i+1} обработана\")\n",
        "\n",
        "# Объединение ответов ассистента в один текст\n",
        "full_assistant_response = '\\n'.join(assistant_responses)\n",
        "wrapped_response = textwrap.fill(full_assistant_response, width=80)\n",
        "print(wrapped_response)\n"
      ],
      "metadata": {
        "id": "gAjwzmkDMMv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение текущей даты в формате ДД-ММ-ГГГГ\n",
        "current_date = datetime.datetime.now().strftime('%d-%m-%Y')\n",
        "\n",
        "# Создание имени файла с текущей датой\n",
        "output_filename = f'Еженедельная встреча вторая итерация саммари {current_date} .txt'\n",
        "\n",
        "# Записать ответы ассистента в файл\n",
        "with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
        "    output_file.write(full_assistant_response)\n",
        "\n",
        "print(f\"Ответы ассистента сохранены в файле: {output_filename}\")"
      ],
      "metadata": {
        "id": "IdJcklW7VvFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWrtcJ9ABZnuCnf0z00qjt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}